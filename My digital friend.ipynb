{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "913edb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "import numpy as np\n",
    "import torch\n",
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "import torchaudio\n",
    "from IPython.display import Audio\n",
    "import moviepy.editor as moviepy\n",
    "import pydub\n",
    "import os\n",
    "from gtts import gTTS\n",
    "import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331d0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speech to text model\n",
    "model_stt = Wav2Vec2ForCTC.from_pretrained(r'yongjian/wav2vec2-large-a') # Note: PyTorch Model\n",
    "processor_stt = Wav2Vec2Processor.from_pretrained(r'yongjian/wav2vec2-large-a')\n",
    "\n",
    "#Conversation model\n",
    "mname = \"facebook/blenderbot-400M-distill\"\n",
    "model_conv = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbc34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stt(audio_file, model_stt = model_stt, processor_stt = processor_stt):\n",
    "    \"\"\"\n",
    "    audio_file: path to audio file to transcribe\n",
    "    returns: transcription\n",
    "    This function is based on Wav2Vec2 by meta\n",
    "    \"\"\"\n",
    "    #read audio\n",
    "    sound = pydub.AudioSegment.from_wav(audio_file)\n",
    "    #need to set framerate = 16k for model\n",
    "    sound = sound.set_frame_rate(16000)\n",
    "    \n",
    "    #convert audio to np and normalize it [-1, 1]\n",
    "    np_wav = np.array(sound.get_array_of_samples()).astype(float)\n",
    "    np_wav /= np_wav.max()\n",
    "    \n",
    "    sample_rate = processor_stt.feature_extractor.sampling_rate\n",
    "    with torch.no_grad():\n",
    "        model_inputs = processor_stt(np_wav, sampling_rate=sample_rate, return_tensors=\"pt\", padding=True)\n",
    "        logits = model_stt(model_inputs.input_values, attention_mask=model_inputs.attention_mask).logits # use .cuda() for GPU acceleration\n",
    "        pred_ids = torch.argmax(logits, dim=-1).cpu()\n",
    "        pred_text = processor_stt.batch_decode(pred_ids)\n",
    "    return pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3c3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(text, model_conv = model_conv, tokenizer = tokenizer):\n",
    "    \"\"\"\n",
    "    text: String of natural language to answer\n",
    "    returns: String of the answer\n",
    "    \"\"\"\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "    reply_ids = model_conv.generate(**inputs)\n",
    "    return tokenizer.batch_decode(reply_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c618efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tts(text):\n",
    "    \"\"\"\n",
    "    text: String of natural language\n",
    "    Saves the audio file in the current directory\n",
    "    \"\"\"\n",
    "    answer = gTTS(text, lang=\"en\", slow=False)\n",
    "    answer.save(\"answer.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0204ddd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429c2c24054742c58bf9473019d57157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Record your audio\n",
    "camera = CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1505e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "You: WHAT ARE YOU DOING FOR FUN\n"
     ]
    }
   ],
   "source": [
    "#Convert webm to wav\n",
    "with open('recording.webm', 'wb') as f:\n",
    "    f.write(recorder.audio.value)\n",
    "moviepy.ffmpeg_tools.ffmpeg_extract_audio(\"recording.webm\", \"wav_file_name.wav\")\n",
    "\n",
    "#Transcription\n",
    "transcript = stt(\"wav_file_name.wav\")[0]\n",
    "print(f\"You: {transcript}\")\n",
    "\n",
    "#play answer\n",
    "answer_text = get_answer(transcript).replace(\"<s>\",\"\").replace(\"</s>\",\"\")\n",
    "tts(answer_text)\n",
    "playsound.playsound(r\"C:\\Users\\rorinr\\Documents\\Programming\\My digital friend\\answer.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
